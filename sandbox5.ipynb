{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchviz import make_dot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# ^ jupyter notebook magic function\n",
    "\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "from torch.jit.annotations import TensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset and dataloaders\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = torchvision.datasets.MNIST(root=os.getcwd(), train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, val, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=os.cpu_count())\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=os.cpu_count())\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter dictionary for each model and \n",
    "# corresponding layer parameters.\n",
    "params: Dict[str,Dict[str,torch.nn]] = {\n",
    "    \"model.1\": {\n",
    "        \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        ),\n",
    "        \"fc_layer\": (nn.Linear(256, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 10),)\n",
    "    },\n",
    "    \"model.2\": {\n",
    "        \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                        ),\n",
    "        \"fc_layer\": (nn.Linear(32, 10),)\n",
    "    },\n",
    "    \"model.3\": {\n",
    "        \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        ),\n",
    "        \"fc_layer\": (nn.Linear(32 * 3 * 3, 10),)\n",
    "    },\n",
    "    \"model.4\": {\n",
    "        \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        ),\n",
    "        \"fc_layer\": (nn.Linear(32 * 7 * 7, 10),)\n",
    "    },\n",
    "    \"model.5\": {\n",
    "        \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        ),\n",
    "        \"fc_layer\": (nn.Linear(14 * 14 * 32, 10))\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model: pl.LightningModule) -> int:\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_and_viz_pl_model(model: Union[nn.Module,pl.LightningModule], filename: str) -> None:\n",
    "    \"\"\"Helper function to visualize and plot the model architecture.\n",
    "\n",
    "    Args:\n",
    "        model: Input pytorch (lightning) model.\n",
    "        filename: Output filename (no file extension).\n",
    "    \"\"\"\n",
    "    # Create a dummy input with the same shape as expected input during training\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "    # Generate the visualization of the model architecture\n",
    "    dot = make_dot(model(dummy_input))\n",
    "    # params = dict(model.named_parameters())\n",
    "\n",
    "    # Save the visualization as an image\n",
    "    dot.format = 'png'\n",
    "    dot.render(filename, cleanup=True)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pt_model(model: Union[nn.Module,pl.LightningModule], filename: str) -> None:\n",
    "    \"\"\"Saves pytorch (lightning) model, and creates visualization of model architecture.\n",
    "\n",
    "    Args:\n",
    "        model: Input pytorch (lightning) model.\n",
    "        filename: Output filename.\n",
    "    \"\"\"\n",
    "    # TODO: Save metadata file for the model.\n",
    "    # Check filename\n",
    "    filename: str\n",
    "    ext: str\n",
    "    \n",
    "    if ('pt' or 'pth') in filename:\n",
    "        filename, ext = os.path.splitext(filename)\n",
    "    else:\n",
    "        ext: str = \".pt\"\n",
    "    \n",
    "    # Save model (and model state)\n",
    "    torch.save(model.state_dict(), f\"{filename}{ext}\")\n",
    "\n",
    "    # Save image of model architecture\n",
    "    _save_and_viz_pl_model(model=model, filename=filename)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pt_model(model: Union[nn.Module,pl.LightningModule], filename: str) -> Union[nn.Module,pl.LightningModule]:\n",
    "    \"\"\"Loads saved/trained model, in which the model class **must** be provided.\n",
    "\n",
    "    Args:\n",
    "        model: Input model class objoect.\n",
    "        filename: Input filename that corresponds to trained saved/trained model.\n",
    "\n",
    "    Returns:\n",
    "        Trained model.\n",
    "    \"\"\"\n",
    "    if ('pt' or 'pth') in filename:\n",
    "        pass\n",
    "    else:\n",
    "        filename: str = f\"{filename}.pt\"\n",
    "\n",
    "    # model = TheModelClass(*args, **kwargs)\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    model.eval() # sets dropout and batch normalization layers to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_norms(model: Union[nn.Module,pl.LightningModule], weight: bool = True, bias: bool = False) -> List[Tuple[str,float]]:\n",
    "    model.eval()\n",
    "    sample_input = torch.randn(1, 1, 28, 28)  # Replace with your own sample input\n",
    "    outputs = model(sample_input)\n",
    "    loss = torch.sum(outputs)  # Create a dummy loss\n",
    "\n",
    "    # Backpropagate to compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Compute gradient norms\n",
    "    gradient_norms: List[Tuple[str,float]] = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            if weight and ('weight' in name):\n",
    "                gradient_norms.append((name, param.grad.norm().item()))\n",
    "            \n",
    "            if bias and ('bias' in name):\n",
    "                gradient_norms.append((name, param.grad.norm().item()))\n",
    "                \n",
    "    return gradient_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layerwise_norms(model: Union[nn.Module,pl.LightningModule], weight: bool = True, bias: bool = False) -> List[Tuple[str,float]]:\n",
    "    model.eval()\n",
    "    sample_input = torch.randn(1, 1, 28, 28)  # Replace with your own sample input\n",
    "    outputs = model(sample_input)\n",
    "    loss = torch.sum(outputs)  # Create a dummy loss\n",
    "\n",
    "    # Backpropagate to compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    layerwise_norms: List[Tuple[str,float]] = []\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name = name #.split('.')[0]  # Extract the layer name\n",
    "        norm = param.norm().item()\n",
    "\n",
    "        if weight and ('weight' in name):\n",
    "            layerwise_norms.append((layer_name, norm))\n",
    "        \n",
    "        if bias and ('bias' in name):\n",
    "            layerwise_norms.append((layer_name, norm))\n",
    "            \n",
    "    return layerwise_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_parameter_norm(model):\n",
    "    total_norm = 0.0\n",
    "    for param in model.parameters():\n",
    "        total_norm += param.norm().item()\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_parameter_norms_per_layer(model, weight: bool = True, bias: bool = False):\n",
    "    norms_per_layer = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name = name #.split('.')[0]  # Extract the layer name\n",
    "        norm = param.norm().item()\n",
    "\n",
    "        if weight and ('weight' in name):\n",
    "            if layer_name not in norms_per_layer:\n",
    "                norms_per_layer[layer_name] = []\n",
    "            norms_per_layer[layer_name].append(norm)\n",
    "        \n",
    "        if bias and ('bias' in name):\n",
    "            if layer_name not in norms_per_layer:\n",
    "                norms_per_layer[layer_name] = []\n",
    "            norms_per_layer[layer_name].append(norm)\n",
    "    return norms_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.5637232363224"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_total_parameter_norm(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0107, -0.4344, -0.4431],\n",
      "          [ 0.3092,  0.9077,  0.6962],\n",
      "          [-0.2895, -0.5783, -0.2747]]],\n",
      "\n",
      "\n",
      "        [[[-0.4840,  0.1207,  0.4232],\n",
      "          [ 0.1232, -0.4691, -0.0978],\n",
      "          [-0.0014,  0.3906, -0.3247]]],\n",
      "\n",
      "\n",
      "        [[[-0.5230,  0.5614,  0.1648],\n",
      "          [-0.6405,  0.7871, -0.2964],\n",
      "          [-0.4766,  0.6181, -0.1111]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2155,  0.4697,  0.5529],\n",
      "          [-0.6010, -0.3685, -0.4876],\n",
      "          [-0.0944, -0.2210,  0.0234]]],\n",
      "\n",
      "\n",
      "        [[[-0.4442, -0.6376,  0.6735],\n",
      "          [-0.5989,  0.7884,  0.2650],\n",
      "          [ 0.8036,  0.4333, -0.5040]]],\n",
      "\n",
      "\n",
      "        [[[-0.0866, -0.4306,  0.2079],\n",
      "          [-0.4045,  0.4508,  0.2470],\n",
      "          [ 0.4847, -0.2742, -0.3739]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4748,  0.4071, -0.4229],\n",
      "          [ 0.2941, -0.0417, -0.7052],\n",
      "          [ 0.6949, -0.3703,  0.1034]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1480,  0.4315, -0.4692],\n",
      "          [-0.1880,  0.4988,  0.3659],\n",
      "          [-0.5237, -0.2290,  0.0537]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6112,  0.3299,  0.4922],\n",
      "          [-0.1249,  0.1678,  0.1815],\n",
      "          [-0.7283, -0.3985, -0.3434]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3351, -0.3882, -0.0543],\n",
      "          [-0.2395,  0.2598, -0.2364],\n",
      "          [ 0.1018,  0.2548, -0.3901]]],\n",
      "\n",
      "\n",
      "        [[[-0.2817, -0.0305,  0.5477],\n",
      "          [ 0.3911,  0.3798, -0.2073],\n",
      "          [ 0.2260, -0.3782, -0.0492]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5469, -0.0062, -0.6850],\n",
      "          [ 0.6616, -0.1997, -0.4467],\n",
      "          [ 0.0771,  0.6272, -0.1547]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4558,  0.1869,  0.0168],\n",
      "          [-0.2699,  0.0787,  0.6862],\n",
      "          [-0.5973, -0.7010,  0.7355]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3675,  0.0625, -0.4139],\n",
      "          [-0.2743, -0.3347,  0.0754],\n",
      "          [-0.3544,  0.2109,  0.1729]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0072, -0.3691, -0.2076],\n",
      "          [-0.3665,  0.2528,  0.3722],\n",
      "          [-0.4208,  0.3040, -0.0253]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0592, -0.5941,  0.0140],\n",
      "          [ 0.4990, -0.3319, -0.4068],\n",
      "          [ 0.4614,  0.3516,  0.2094]]],\n",
      "\n",
      "\n",
      "        [[[-0.4766, -0.0935,  0.3472],\n",
      "          [ 0.6703,  0.4183,  0.2670],\n",
      "          [ 0.0979, -0.4773, -0.4300]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2261,  0.4393,  0.1192],\n",
      "          [ 0.1053,  0.2681, -0.0539],\n",
      "          [ 0.4395,  0.3338, -0.5976]]],\n",
      "\n",
      "\n",
      "        [[[-0.4497,  0.0061,  0.5263],\n",
      "          [-0.4008,  0.1645,  0.2090],\n",
      "          [-0.3395,  0.8364, -0.2412]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0236,  0.4986,  0.1899],\n",
      "          [-0.4312,  0.3752, -0.5155],\n",
      "          [ 0.3445,  0.4867, -0.2291]]],\n",
      "\n",
      "\n",
      "        [[[-0.1160,  0.2703,  0.2793],\n",
      "          [ 0.2213,  0.2559, -0.1384],\n",
      "          [-0.3678, -0.3680, -0.3567]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7748,  0.4537, -0.2524],\n",
      "          [-0.1112,  0.4770, -0.1379],\n",
      "          [-0.7154,  0.0960,  1.0171]]],\n",
      "\n",
      "\n",
      "        [[[-0.6360, -0.5811, -0.3799],\n",
      "          [ 0.4066, -0.1047, -0.2993],\n",
      "          [ 0.3807,  0.6725,  0.0700]]],\n",
      "\n",
      "\n",
      "        [[[-0.2483, -0.0466,  0.1193],\n",
      "          [-0.3641,  0.0559,  0.4096],\n",
      "          [ 0.0093, -0.2118,  0.2342]]],\n",
      "\n",
      "\n",
      "        [[[-0.1378,  0.1221,  0.0697],\n",
      "          [-0.0714, -0.0446, -0.1053],\n",
      "          [ 0.2547, -0.1689,  0.1748]]],\n",
      "\n",
      "\n",
      "        [[[-0.3196, -0.2059,  0.0623],\n",
      "          [-0.5330,  0.2384, -0.0295],\n",
      "          [ 0.3906,  0.5536, -0.5861]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1837, -0.3912, -1.0620],\n",
      "          [ 0.3264,  0.8573,  0.0874],\n",
      "          [-0.1796,  0.0833,  1.1337]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4996, -0.3165,  0.4447],\n",
      "          [-0.4821, -0.1601, -0.3036],\n",
      "          [ 0.2141,  0.2383, -0.0034]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0532, -0.5392,  0.5353],\n",
      "          [ 0.5345, -0.5030, -0.0605],\n",
      "          [-0.0864, -0.3281,  0.3270]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1740, -0.1147,  0.4937],\n",
      "          [ 0.3745,  0.1601,  0.5773],\n",
      "          [-0.4259, -0.4529, -0.4652]]],\n",
      "\n",
      "\n",
      "        [[[-0.3212,  0.2491,  0.4446],\n",
      "          [ 0.4180, -0.2679, -0.5490],\n",
      "          [ 0.1910, -0.4400,  0.5347]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1669,  0.6041, -0.7407],\n",
      "          [-0.1941, -0.2538,  0.1706],\n",
      "          [-0.1776, -0.2009,  0.4680]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1424, -0.4016, -0.3263, -0.5042, -0.4917, -0.2270, -0.5374, -0.2955,\n",
      "        -0.4741, -0.4106, -0.2271, -0.4632, -0.4850, -0.4557, -0.4980, -0.2736,\n",
      "        -0.2263, -0.4901, -0.3753, -0.1828, -0.3393, -0.3849, -0.4788, -0.3233,\n",
      "        -0.1063, -0.4835, -0.5140, -0.1379, -0.0839, -0.4089, -0.1568, -0.2183],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0507,  0.0904,  0.0786,  ...,  0.0022,  0.0290,  0.0062],\n",
      "        [ 0.0310,  0.0387,  0.0506,  ...,  0.0190,  0.0289,  0.0285],\n",
      "        [-0.0999, -0.1237, -0.1292,  ...,  0.0600,  0.0302,  0.0537],\n",
      "        ...,\n",
      "        [-0.0641, -0.1378, -0.1262,  ...,  0.0260,  0.0437,  0.0466],\n",
      "        [ 0.0336,  0.0558,  0.0688,  ..., -0.0549, -0.0317, -0.0280],\n",
      "        [ 0.1167,  0.0475,  0.0373,  ..., -0.0206, -0.0924, -0.0653]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0101,  0.1583,  0.0346, -0.0318, -0.0143,  0.0559, -0.0101,  0.0664,\n",
      "        -0.1107, -0.0471], requires_grad=True)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LightningModule\n",
    "class ConvNet(pl.LightningModule):\n",
    "    def __init__(self, params: Dict[str,torch.nn]):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            *params.get('conv_layers')\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            self.fc_layer = nn.Sequential(\n",
    "                *params.get('fc_layer')\n",
    "            )\n",
    "        except TypeError:\n",
    "            self.fc_layer = nn.Sequential(\n",
    "                params.get('fc_layer')\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    # Define the training step method\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    # Define the validation step method\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.log('val_loss', loss, prog_bar=True)  # Logging the validation loss\n",
    "    \n",
    "    # Define the test step method\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.log('test_loss', loss)  # Logging the test loss\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = (preds == targets).float().mean()\n",
    "        self.log('test_acc', acc, prog_bar=True)  # Logging the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer object\n",
    "trainer = pl.Trainer(accelerator='mps',max_epochs=10,devices=1)  # Set max_epochs and gpus according to your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in params.keys():\n",
    "    # Print Model number to screen\n",
    "    print(f\"\\n{param}:\\n\")\n",
    "    \n",
    "    # Initialize the Lightning Trainer\n",
    "    model = ConvNet(params=params.get(param))\n",
    "    # trainer = pl.Trainer(accelerator='mps',max_epochs=10,devices=1)  # Set max_epochs and gpus according to your environment\n",
    "\n",
    "    # Train the model using PyTorch Lightning\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # Save trained model\n",
    "    save_pt_model(model=model,filename=f\"models/{param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict: Dict[str,Dict[str,Any]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model.1:\n",
      "\n",
      "Training accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adebayobraimah/Desktop/projects/fall2023project/.env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:480: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059a3ea38228436cb8561de6ae3589f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.995270848274231     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01704791933298111    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.995270848274231    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01704791933298111   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e3740b8343401798eb95ef77a9c0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9863333106040955     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08278840780258179    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9863333106040955    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08278840780258179   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 422,026\n",
      "\n",
      "model.2:\n",
      "\n",
      "Training accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd03781b02c4448a9222c04b24aa2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9964583516120911     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01097323838621378    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9964583516120911    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01097323838621378   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e207feccf71407bb1acbbf9d606fd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9869999885559082     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0553138442337513     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9869999885559082    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0553138442337513    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 28,394\n",
      "\n",
      "model.3:\n",
      "\n",
      "Training accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044000fe45534eea853c4f28c5680365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9959375262260437     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.011619341559708118    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9959375262260437    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.011619341559708118   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3826b251294a628e90043b1ff6f4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9833333492279053     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0808323547244072     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9833333492279053    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0808323547244072    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 21,706\n",
      "\n",
      "model.4:\n",
      "\n",
      "Training accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb3e165c3a84480824d141286ef7dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9977708458900452     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.006235057022422552    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9977708458900452    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.006235057022422552   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea12a2be29b46d687f61a8d1bcba1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9851666688919067     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08124293386936188    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9851666688919067    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08124293386936188   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 25,258\n",
      "\n",
      "model.5:\n",
      "\n",
      "Training accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29882d7efd4646efa6c1fd9393b6402d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9970208406448364     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.008239409886300564    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9970208406448364    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.008239409886300564   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48fa59c5b0b44d0a6abc06229e8ef46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9776666760444641     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10316558182239532    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9776666760444641    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10316558182239532   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 63,050\n"
     ]
    }
   ],
   "source": [
    "for param in params.keys():\n",
    "    # Print Model number to screen\n",
    "    print(f\"\\n{param}:\\n\")\n",
    "\n",
    "    tmp_dict = {}\n",
    "\n",
    "    # Load model\n",
    "    model = load_pt_model(model=ConvNet(params=params.get(param)),filename=f\"models/{param}\")\n",
    "    # trainer = pl.Trainer(accelerator='mps',max_epochs=10,devices=1)  # Set max_epochs and gpus according to your environment\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    print(f\"Training accuracy:\")\n",
    "    train_results = trainer.test(model, dataloaders=train_loader)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    print(f\"Testing accuracy:\")\n",
    "    test_results = trainer.test(model, dataloaders=test_loader)\n",
    "\n",
    "    # Countable parameters\n",
    "    print(f\"Number of trainable parameters (weights): {count_trainable_parameters(model=model):,}\")\n",
    "    countable_parameters: str = f\"{count_trainable_parameters(model=model):,}\"\n",
    "\n",
    "    # Gradient Norms\n",
    "    grad_norms = get_gradient_norms(model=model, weight=True)\n",
    "\n",
    "    # Layerwise Norms\n",
    "    layer_norms = get_layerwise_norms(model=model, weight=True)\n",
    "\n",
    "    tmp_dict = {\n",
    "        \"train_acc\": f\"{train_results[0].get('test_acc'):.4f}\",\n",
    "        \"test_acc\": f\"{test_results[0].get('test_acc'):.4f}\",\n",
    "        \"parameters\": countable_parameters,\n",
    "        \"grad_norm\": grad_norms,\n",
    "        \"layer_norm\": layer_norms,\n",
    "    }\n",
    "\n",
    "    results_dict.update({param:tmp_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adebayobraimah/Desktop/projects/fall2023project/.env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:480: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08a2f8767e149ab9550f278d04148af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9970208406448364     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.00823940895497799    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9970208406448364    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.00823940895497799   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.test(model, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.1': {'train_acc': '0.9953',\n",
       "  'test_acc': '0.9863',\n",
       "  'parameters': '422,026',\n",
       "  'grad_norm': [('conv_layers.0.weight', 42.79999542236328),\n",
       "   ('conv_layers.3.weight', 66.82827758789062),\n",
       "   ('conv_layers.6.weight', 79.48753356933594),\n",
       "   ('conv_layers.9.weight', 101.20499420166016),\n",
       "   ('fc_layer.0.weight', 56.832176208496094),\n",
       "   ('fc_layer.2.weight', 33.2569694519043)],\n",
       "  'layer_norm': [('conv_layers.0.weight', 3.758045196533203),\n",
       "   ('conv_layers.3.weight', 16.317190170288086),\n",
       "   ('conv_layers.6.weight', 28.013669967651367),\n",
       "   ('conv_layers.9.weight', 38.37032699584961),\n",
       "   ('fc_layer.0.weight', 13.226685523986816),\n",
       "   ('fc_layer.2.weight', 4.223467826843262)]},\n",
       " 'model.2': {'train_acc': '0.9965',\n",
       "  'test_acc': '0.9870',\n",
       "  'parameters': '28,394',\n",
       "  'grad_norm': [('conv_layers.0.weight', 52.87578201293945),\n",
       "   ('conv_layers.3.weight', 81.1396484375),\n",
       "   ('conv_layers.6.weight', 123.01580810546875),\n",
       "   ('conv_layers.9.weight', 209.22975158691406),\n",
       "   ('fc_layer.0.weight', 239.206787109375)],\n",
       "  'layer_norm': [('conv_layers.0.weight', 5.238247871398926),\n",
       "   ('conv_layers.3.weight', 14.022479057312012),\n",
       "   ('conv_layers.6.weight', 11.472160339355469),\n",
       "   ('conv_layers.9.weight', 9.821552276611328),\n",
       "   ('fc_layer.0.weight', 3.079420804977417)]},\n",
       " 'model.3': {'train_acc': '0.9959',\n",
       "  'test_acc': '0.9833',\n",
       "  'parameters': '21,706',\n",
       "  'grad_norm': [('conv_layers.0.weight', 152.1088104248047),\n",
       "   ('conv_layers.3.weight', 268.0559997558594),\n",
       "   ('conv_layers.6.weight', 265.9255065917969),\n",
       "   ('fc_layer.0.weight', 314.8031005859375)],\n",
       "  'layer_norm': [('conv_layers.0.weight', 4.939901351928711),\n",
       "   ('conv_layers.3.weight', 13.342869758605957),\n",
       "   ('conv_layers.6.weight', 11.952005386352539),\n",
       "   ('fc_layer.0.weight', 7.1646504402160645)]},\n",
       " 'model.4': {'train_acc': '0.9978',\n",
       "  'test_acc': '0.9852',\n",
       "  'parameters': '25,258',\n",
       "  'grad_norm': [('conv_layers.0.weight', 324.3822937011719),\n",
       "   ('conv_layers.3.weight', 535.0931396484375),\n",
       "   ('fc_layer.0.weight', 277.4189758300781)],\n",
       "  'layer_norm': [('conv_layers.0.weight', 5.692054748535156),\n",
       "   ('conv_layers.3.weight', 13.9744873046875),\n",
       "   ('fc_layer.0.weight', 15.50316047668457)]},\n",
       " 'model.5': {'train_acc': '0.9970',\n",
       "  'test_acc': '0.9777',\n",
       "  'parameters': '63,050',\n",
       "  'grad_norm': [('conv_layers.0.weight', 418.56280517578125),\n",
       "   ('fc_layer.0.weight', 290.2900695800781)],\n",
       "  'layer_norm': [('conv_layers.0.weight', 6.930140018463135),\n",
       "   ('fc_layer.0.weight', 37.295448303222656)]}}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9970'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results[0].get(\"test_acc\").4f\n",
    "f\"{results[0].get('test_acc'):.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.randn(1, 1, 28, 28)  # Replace with your own sample input\n",
    "outputs = model(sample_input)\n",
    "loss = torch.sum(outputs)  # Create a dummy loss\n",
    "\n",
    "# Backpropagate to compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layers.0.weight 403.0003967285156\n",
      "conv_layers.0.bias 340.44183349609375\n",
      "fc_layer.0.weight 305.35125732421875\n",
      "fc_layer.0.bias 3.1622776985168457\n"
     ]
    }
   ],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    print(name, param.grad.norm().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_norms(model: Union[nn.Module,pl.LightningModule], weight: bool = True, bias: bool = False) -> List[Tuple[str,float]]:\n",
    "    model.eval()\n",
    "    sample_input = torch.randn(1, 1, 28, 28)  # Replace with your own sample input\n",
    "    outputs = model(sample_input)\n",
    "    loss = torch.sum(outputs)  # Create a dummy loss\n",
    "\n",
    "    # Backpropagate to compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Compute gradient norms\n",
    "    gradient_norms: List[Tuple[str,float]] = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            if weight and ('weight' in name):\n",
    "                gradient_norms.append((name, param.grad.norm().item()))\n",
    "            \n",
    "            if bias and ('bias' in name):\n",
    "                gradient_norms.append((name, param.grad.norm().item()))\n",
    "                \n",
    "    return gradient_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layerwise_norms(model: Union[nn.Module,pl.LightningModule], weight: bool = True, bias: bool = False) -> List[Tuple[str,float]]:\n",
    "    model.eval()\n",
    "    sample_input = torch.randn(1, 1, 28, 28)  # Replace with your own sample input\n",
    "    outputs = model(sample_input)\n",
    "    loss = torch.sum(outputs)  # Create a dummy loss\n",
    "\n",
    "    # Backpropagate to compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    layerwise_norms: List[Tuple[str,float]] = []\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name = name #.split('.')[0]  # Extract the layer name\n",
    "        norm = param.norm().item()\n",
    "\n",
    "        if weight and ('weight' in name):\n",
    "            layerwise_norms.append((layer_name, norm))\n",
    "        \n",
    "        if bias and ('bias' in name):\n",
    "            layerwise_norms.append((layer_name, norm))\n",
    "            \n",
    "    return layerwise_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv_layers.0.weight', 6.930140018463135),\n",
       " ('conv_layers.0.bias', 2.115267038345337),\n",
       " ('fc_layer.0.weight', 37.295448303222656),\n",
       " ('fc_layer.0.bias', 0.22286787629127502)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_layerwise_norms(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv_layers.0.weight', 403.0003967285156),\n",
       " ('conv_layers.0.bias', 340.44183349609375),\n",
       " ('fc_layer.0.weight', 305.35125732421875),\n",
       " ('fc_layer.0.bias', 3.1622776985168457)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_norms(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c2e05a90>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchray.attribution.grad_cam import grad_cam\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradcam(model, input_image, target_class):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Convert the input image to a PIL Image if it's a numpy array\n",
    "    if isinstance(input_image, np.ndarray):\n",
    "        input_image = Image.fromarray(input_image)\n",
    "    elif isinstance(input_image, torch.Tensor):\n",
    "        input_image = (torch.as_tensor(input_image.reshape(28,28)).numpy())\n",
    "        input_image = Image.fromarray((input_image * 255).astype(np.uint8))\n",
    "\n",
    "    # Apply preprocessing transformations to the input image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    input_tensor = transform(input_image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Compute GradCAM\n",
    "    cam = grad_cam(model, input_tensor, target_class)\n",
    "\n",
    "    # Normalize the GradCAM heatmap\n",
    "    cam_normalized = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "    return cam_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.9843, -0.9294, -0.9922, -0.9373, -0.3255, -0.8902,\n",
       "          -0.9922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.9451,  0.3333,  0.9922,  0.4745,  0.9373,  0.9922,  0.9922,\n",
       "          -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8196,\n",
       "           0.6157,  0.9922,  0.9922,  0.8824,  0.4824,  0.4118,  0.9922,\n",
       "           0.4039, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7647,  0.6157,\n",
       "           0.9922,  0.9608,  0.3333, -0.9373, -1.0000, -0.4667,  0.9922,\n",
       "           0.4039, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.9765,  0.0196,  0.8980,  0.9922,\n",
       "           0.9608, -0.2000, -1.0000, -1.0000, -1.0000, -0.4039,  0.9922,\n",
       "           0.4039, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000,  0.0275,  0.9922,  0.9922,  0.9608,\n",
       "          -0.1922, -1.0000, -1.0000, -1.0000, -1.0000,  0.1765,  0.9922,\n",
       "           0.1137, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.0902,  0.8196,  0.4196, -0.5294,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.7020,  0.9922,\n",
       "          -0.3333, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.8667, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.7569,  0.9137,  0.9922,\n",
       "          -0.9059, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.0667,  0.9922,  0.7176,\n",
       "          -0.9529, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.9137,  0.8431,  0.9922, -0.2235,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.9137,  0.6235,  0.9922,  0.5922, -0.9373,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.8039, -0.4824,  0.0824,  0.0824,\n",
       "           0.0824,  0.0824,  0.2784,  0.9922,  0.8902, -0.7882, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -0.6000,  0.1765,  0.8745,  0.9922,  0.9922,  0.9922,\n",
       "           0.9922,  0.9922,  0.9922,  0.9922,  0.7804, -0.9059, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8196, -0.0039,\n",
       "           0.8039,  0.9451,  0.7176, -0.1451, -0.2314, -0.8039, -0.1843,\n",
       "           0.9922,  0.9922,  0.9922,  0.8353,  0.9922,  0.6471, -0.7647,\n",
       "          -1.0000, -0.5137, -0.6627, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.6314,  0.6941,  0.9922,\n",
       "           0.7882, -0.0118, -0.7490, -0.7647, -0.3804,  0.4902,  0.9686,\n",
       "           0.9922,  0.7176, -0.4510, -0.7412,  0.5373,  0.9922,  0.8980,\n",
       "          -0.1922,  0.9529,  0.7255, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.5294,  0.9922,  0.9922,\n",
       "           0.4745,  0.2157,  0.4980,  0.9294,  0.9922,  0.9922,  0.9059,\n",
       "           0.0980, -0.8431, -1.0000, -1.0000, -0.9686,  0.2627,  0.9922,\n",
       "           0.9922,  0.9922,  0.5922, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.5922,  0.9922,  0.9922,\n",
       "           0.9922,  0.9922,  0.9922,  0.9922,  0.5294, -0.1216, -0.8039,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9686, -0.5059,\n",
       "          -0.2471, -0.2471, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.9451, -0.2784, -0.2784,\n",
       "          -0.2784, -0.2784, -0.5608, -0.9373, -0.9843, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(image,torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "grad_cam() missing 1 required keyword-only argument: 'saliency_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cam \u001b[39m=\u001b[39m compute_gradcam(model, image, label)\n",
      "Cell \u001b[0;32mIn[172], line 20\u001b[0m, in \u001b[0;36mcompute_gradcam\u001b[0;34m(model, input_image, target_class)\u001b[0m\n\u001b[1;32m     17\u001b[0m input_tensor \u001b[39m=\u001b[39m transform(input_image)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)  \u001b[39m# Add batch dimension\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# Compute GradCAM\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m cam \u001b[39m=\u001b[39m grad_cam(model, input_tensor, target_class)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Normalize the GradCAM heatmap\u001b[39;00m\n\u001b[1;32m     23\u001b[0m cam_normalized \u001b[39m=\u001b[39m (cam \u001b[39m-\u001b[39m cam\u001b[39m.\u001b[39mmin()) \u001b[39m/\u001b[39m (cam\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m cam\u001b[39m.\u001b[39mmin())\n",
      "\u001b[0;31mTypeError\u001b[0m: grad_cam() missing 1 required keyword-only argument: 'saliency_layer'"
     ]
    }
   ],
   "source": [
    "cam = compute_gradcam(model, image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = (torch.as_tensor(input_image.reshape(28,28)).numpy())\n",
    "input_image = Image.fromarray((input_image * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAK1NA8Pap4n1SPTtJtWuLh+w4Cj1JPAFbmt/D+fRvD9zqo1rS74Wl2LaeOzkaQKWzsIfG05wSRnIGM8nA4+iut0jxtr3h7wxLpmjW8VjFeF1nvoYT58/TjzCTjaDgbcY3Z6nJ2tXs4PC/wdstNuXb+19bu0v3tnZh5MChlRgAdvzcHnnnpwCPOK7L4d3Hg621O7k8XoxjWINaExNIgkB/iVT8w6HB4OCD159Au/jPpuhW0sfhz7VeXQZ/KMkK21kgdtzlYVO7jA27iT8zZPrzKfEzSteW4ufG/h6LVdSjRhZXEA8vGQ3ySDOCoJGDgke/FeZ0UUUV//9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABIUlEQVR4AWNkZMANmHBLMTBQT5JFiElgrQzMPEYUwB/6t/L937+JEEEGFDn9uX//PqzO/JuORdJ27t+voYKMXTBJFoRX2P6tkPhxcw0DgwBcDGEs+9+/Xy+AuLp/ZTGMfXUxuxIsuPnvGgxJRmWIkP3Lv5KYkhARxg9/t/NCmDDvwt3AIPacQfALlAtVDqfE5/+dLgjlIQWCcZsoELj/fWwOUwmXTNe9/xcCjkOdw8gIkdRnOPtx+51jxpeA0lf/LrVlrA0H6QZLxm/8e/Kfo+2C2u9/t/c5d/59euHzTrhk+9+/leb1b//+fS6pycjI6QzUPx0uOR1iWfsjY5AQI2f9oUPCYBYogfGtBhLbF3z5g/AtmAW0FTfADCEktQMhCQAx52oga0mPsgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "f is 55"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(f\"f is {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN = f\"\"\"\n",
    "\n",
    "| model \\ specifications | Train Accuracy | Test Accuracy | Number of Parameters | Gradient Norm | Layerwise Norm | Total Parameter Norm | Per Layer Parameter Norm |\n",
    "|------------------------|----------------|---------------|----------------------|---------------|----------------|----------------------|--------------------------|\n",
    "| 1                      |                |               |                      |               |                |                      |                          |\n",
    "| 2                      |                |               |                      |               |                |                      |                          |\n",
    "| 3                      |                |               |                      |               |                |                      |                          |\n",
    "| 4                      |                |               |                      |               |                |                      |                          |\n",
    "| 5                      |                |               |                      |               |                |                      |                          |\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "| model \\ specifications | Train accuracy | Test accuracy | Number of parameters | Gradient Norm | Layerwise Norm |\n",
       "|------------------------|----------------|---------------|----------------------|---------------|----------------|\n",
       "| 1                      | [('conv_layers.0.weight', 6.930140018463135), ('fc_layer.0.weight', 37.295448303222656)]               |               |                      |               |                |\n",
       "| 2                      |                |               |                      |               |                |\n",
       "| 3                      |                |               |                      |               |                |\n",
       "| 4                      |                |               |                      |               |                |\n",
       "| 5                      |                |               |                      |               |                |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(MARKDOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
