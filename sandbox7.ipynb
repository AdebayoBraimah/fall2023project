{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchviz import make_dot\n",
    "\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "from torch.jit.annotations import TensorType\n",
    "\n",
    "from IPython.display import Markdown as md # For automated updates of the table\n",
    "\n",
    "import pickle # tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset and dataloaders\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = torchvision.datasets.MNIST(root=os.getcwd(), train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, val, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=os.cpu_count())\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=os.cpu_count())\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "Below is a dictionary of the models used for the experiment, with different numbers of convolutional layers and fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter dictionary for each model and \n",
    "# corresponding layer parameters.\n",
    "params: Dict[str,Dict[str,torch.nn]] = {\n",
    "    # \"model.1\": {\n",
    "    #     \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #                     nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #                     nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #                     nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #                     ),\n",
    "    #     \"fc_layer\": (nn.Linear(256, 128),\n",
    "    #                  nn.ReLU(),\n",
    "    #                  nn.Linear(128, 10),)\n",
    "    # },\n",
    "    \"model.2\": {\n",
    "        \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                        nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                        ),\n",
    "        \"fc_layer\": (\n",
    "                     nn.Linear(32, 32),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(32, 10),\n",
    "                     )\n",
    "    },\n",
    "    # \"model.3\": {\n",
    "    #     \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #                     nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #                     nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #                     ),\n",
    "    #     \"fc_layer\": (nn.Linear(128 * 3 * 3, 256),\n",
    "    #                  nn.ReLU(),\n",
    "    #                  nn.Linear(256, 10))\n",
    "    # },\n",
    "    # \"model.4\": {\n",
    "    #     \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #                     nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    #                     ),\n",
    "    #     \"fc_layer\": (nn.Linear(64 * 7 * 7, 128),\n",
    "    #                  nn.ReLU(),\n",
    "    #                  nn.Linear(128, 10)\n",
    "    #                  )\n",
    "    # },\n",
    "    # \"model.5\": {\n",
    "    #     \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #                     ),\n",
    "    #     \"fc_layer\": (nn.Linear(32 * 14 * 14, 128),\n",
    "    #                  nn.ReLU(),\n",
    "    #                  nn.Linear(128, 10)\n",
    "    #                  )\n",
    "    # },\n",
    "    # \"model.6\": {\n",
    "    #     \"conv_layers\": (nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "    #                     nn.ReLU(),\n",
    "    #                     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #                     ),\n",
    "    #     \"fc_layer\": (nn.Linear(14 * 14 * 32, 10))\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model: pl.LightningModule) -> int:\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_and_viz_pl_model(model: Union[nn.Module,pl.LightningModule], filename: str) -> None:\n",
    "    \"\"\"Helper function to visualize and plot the model architecture.\n",
    "\n",
    "    Args:\n",
    "        model: Input pytorch (lightning) model.\n",
    "        filename: Output filename (no file extension).\n",
    "    \"\"\"\n",
    "    # Create a dummy input with the same shape as expected input during training\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "    # Generate the visualization of the model architecture\n",
    "    dot = make_dot(model(dummy_input))\n",
    "    # params = dict(model.named_parameters())\n",
    "\n",
    "    # Save the visualization as an image\n",
    "    dot.format = 'png'\n",
    "    dot.render(filename, cleanup=True)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pt_model(model: Union[nn.Module,pl.LightningModule], filename: str) -> None:\n",
    "    \"\"\"Saves pytorch (lightning) model, and creates visualization of model architecture.\n",
    "\n",
    "    Args:\n",
    "        model: Input pytorch (lightning) model.\n",
    "        filename: Output filename.\n",
    "    \"\"\"\n",
    "    # TODO: Save metadata file for the model.\n",
    "    # Check filename\n",
    "    filename: str\n",
    "    ext: str\n",
    "    \n",
    "    if ('pt' or 'pth') in filename:\n",
    "        filename, ext = os.path.splitext(filename)\n",
    "    else:\n",
    "        ext: str = \".pt\"\n",
    "    \n",
    "    # Save model (and model state)\n",
    "    torch.save(model.state_dict(), f\"{filename}{ext}\")\n",
    "\n",
    "    # Pickle test\n",
    "    # with open(f\"{filename}{ext}\",'wb') as f:\n",
    "    #     pickle.dump(model,f)\n",
    "\n",
    "    # Save image of model architecture\n",
    "    _save_and_viz_pl_model(model=model, filename=filename)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pt_model(model: Union[nn.Module,pl.LightningModule], filename: str) -> Union[nn.Module,pl.LightningModule]:\n",
    "    \"\"\"Loads saved/trained model, in which the model class **must** be provided.\n",
    "\n",
    "    Args:\n",
    "        model: Input model class objoect.\n",
    "        filename: Input filename that corresponds to trained saved/trained model.\n",
    "\n",
    "    Returns:\n",
    "        Trained model.\n",
    "    \"\"\"\n",
    "    if ('pt' or 'pth') in filename:\n",
    "        pass\n",
    "    else:\n",
    "        filename: str = f\"{filename}.pt\"\n",
    "\n",
    "    # # Pickle test\n",
    "    # with open(filename,'rb') as f:\n",
    "    #     pickle.load(f)\n",
    "\n",
    "    # Load model\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    model.eval() # sets dropout and batch normalization layers to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_norms(model: Union[nn.Module,pl.LightningModule], weight: bool = True, bias: bool = False) -> List[Tuple[str,float]]:\n",
    "    model.eval()\n",
    "    sample_input = torch.randn(1, 1, 28, 28)  # Replace with your own sample input\n",
    "    outputs = model(sample_input)\n",
    "    loss = torch.sum(outputs)  # Create a dummy loss\n",
    "\n",
    "    # Backpropagate to compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Compute gradient norms\n",
    "    gradient_norms: List[Tuple[str,float]] = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            if weight and ('weight' in name):\n",
    "                gradient_norms.append((name, param.grad.norm().item()))\n",
    "            \n",
    "            if bias and ('bias' in name):\n",
    "                gradient_norms.append((name, param.grad.norm().item()))\n",
    "                \n",
    "    return gradient_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layerwise_norms(model: Union[nn.Module,pl.LightningModule], weight: bool = True, bias: bool = False) -> List[Tuple[str,float]]:\n",
    "    model.eval()\n",
    "    sample_input = torch.randn(1, 1, 28, 28)  # Replace with your own sample input\n",
    "    outputs = model(sample_input)\n",
    "    loss = torch.sum(outputs)  # Create a dummy loss\n",
    "\n",
    "    # Backpropagate to compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    layerwise_norms: List[Tuple[str,float]] = []\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name = name #.split('.')[0]  # Extract the layer name\n",
    "        norm = param.norm().item()\n",
    "\n",
    "        if weight and ('weight' in name):\n",
    "            layerwise_norms.append((layer_name, norm))\n",
    "        \n",
    "        if bias and ('bias' in name):\n",
    "            layerwise_norms.append((layer_name, norm))\n",
    "            \n",
    "    return layerwise_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_parameter_norm(model):\n",
    "    total_norm = 0.0\n",
    "    for param in model.parameters():\n",
    "        total_norm += param.norm().item()\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_parameter_norms_per_layer(model, weight: bool = True, bias: bool = False):\n",
    "    norms_per_layer = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name = name #.split('.')[0]  # Extract the layer name\n",
    "        norm = param.norm().item()\n",
    "\n",
    "        if weight and ('weight' in name):\n",
    "            if layer_name not in norms_per_layer:\n",
    "                norms_per_layer[layer_name] = []\n",
    "            norms_per_layer[layer_name].append(norm)\n",
    "        \n",
    "        if bias and ('bias' in name):\n",
    "            if layer_name not in norms_per_layer:\n",
    "                norms_per_layer[layer_name] = []\n",
    "            norms_per_layer[layer_name].append(norm)\n",
    "    return norms_per_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LightningModule\n",
    "class ConvNet(pl.LightningModule):\n",
    "    def __init__(self, params: Dict[str,torch.nn]):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            *params.get('conv_layers')\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            self.fc_layer = nn.Sequential(\n",
    "                *params.get('fc_layer')\n",
    "            )\n",
    "        except TypeError:\n",
    "            self.fc_layer = nn.Sequential(\n",
    "                params.get('fc_layer')\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    # Define the training step method\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    # Define the validation step method\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.log('val_loss', loss, prog_bar=True)  # Logging the validation loss\n",
    "    \n",
    "    # Define the test step method\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.log('test_loss', loss)  # Logging the test loss\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = (preds == targets).float().mean()\n",
    "        self.log('test_acc', acc, prog_bar=True)  # Logging the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(*args):\n",
    "    # for arg in args:\n",
    "    #     print(arg)\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Linear(in_features=32, out_features=10, bias=True),)\n"
     ]
    }
   ],
   "source": [
    "a(*params.get('model.2').get('fc_layer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Create trainer object\n",
    "trainer = pl.Trainer(accelerator='mps',max_epochs=10,devices=1)  # Set max_epochs and gpus according to your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type       | Params\n",
      "-------------------------------------------\n",
      "0 | conv_layers | Sequential | 28.1 K\n",
      "1 | fc_layer    | Sequential | 330   \n",
      "-------------------------------------------\n",
      "28.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.4 K    Total params\n",
      "0.114     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model.2:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38f21715fb54fde81008bb543bc5ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fce1b4600c4780a46e361286514a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a676d898739745358bfcd3f22c92cecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e4cc5d8cdb4bf6849111ffc87f9512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18886ff4cd4544e293520464240405df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04942c92c418400184be35ad60e3828d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a6a0391a064adf940465bf8fc7a48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eccdddfdee94beba8f394735ace6281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d65ae00c10544dc905415387afe659c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c2fe0194bc4a6ebc201cca4e45df48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ba6b3f4f5549d18889140d1a7df92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b778d1cc872245fda9ce18debccabfd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "MARKDOWN: str = \"\"\n",
    "\n",
    "for param in params.keys():\n",
    "    # Print Model number to screen\n",
    "    print(f\"\\n{param}:\\n\")\n",
    "    \n",
    "    # Initialize the Lightning Trainer\n",
    "    model = ConvNet(params=params.get(param))\n",
    "\n",
    "    # Train the model using PyTorch Lightning\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # Save trained model\n",
    "    save_pt_model(model=model,filename=f\"models/{param}\")\n",
    "\n",
    "    MARKDOWN += f\"### {param}: \\n\\n![](models/{param}.png)\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model architecture diagrams\n",
    "md(MARKDOWN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Models' Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict: Dict[str,Dict[str,Any]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model.2:\n",
      "\n",
      "Training accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adebayobraimah/Desktop/projects/fall2023project/.env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:480: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826c15daaf184b128d76648ba3888007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9939791560173035     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.018502390012145042    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9939791560173035    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.018502390012145042   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df87592bf6e844ad8b97c6c909a23f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9848333597183228     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06702698022127151    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9848333597183228    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06702698022127151   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 28,394\n"
     ]
    }
   ],
   "source": [
    "# Norm calcuation booleans\n",
    "weight: bool = True\n",
    "bias: bool = False\n",
    "\n",
    "for param in params.keys():\n",
    "    # Print Model number to screen\n",
    "    print(f\"\\n{param}:\\n\")\n",
    "\n",
    "    tmp_dict = {}\n",
    "\n",
    "    # # Initialize the Lightning Trainer\n",
    "    # model = ConvNet(params=params.get(param))\n",
    "\n",
    "    # # Train the model using PyTorch Lightning\n",
    "    # trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # Load model\n",
    "    model = load_pt_model(model=ConvNet(params=params.get(param)),filename=f\"models/{param}\")\n",
    "    trainer = pl.Trainer(accelerator='mps',max_epochs=10,devices=1)  # Set max_epochs and gpus according to your environment\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    print(f\"Training accuracy:\")\n",
    "    train_results = trainer.test(model, dataloaders=train_loader)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    print(f\"Testing accuracy:\")\n",
    "    test_results = trainer.test(model, dataloaders=test_loader)\n",
    "\n",
    "    # Countable parameters\n",
    "    print(f\"Number of trainable parameters (weights): {count_trainable_parameters(model=model):,}\")\n",
    "    countable_parameters: str = f\"{count_trainable_parameters(model=model):,}\"\n",
    "\n",
    "    # Gradient Norms\n",
    "    grad_norms = get_gradient_norms(model=model, weight=weight, bias=bias)\n",
    "\n",
    "    # Layerwise Norms\n",
    "    layer_norms = get_layerwise_norms(model=model, weight=weight, bias=bias)\n",
    "\n",
    "    # Total parameter norm\n",
    "    total_norm = calculate_total_parameter_norm(model=model)\n",
    "\n",
    "    # Parameter norms per layer\n",
    "    norms_per_layer = calculate_parameter_norms_per_layer(model=model, weight=weight, bias=bias)\n",
    "\n",
    "    tmp_dict = {\n",
    "        \"train_acc\": f\"{train_results[0].get('test_acc'):.4f}\",\n",
    "        \"test_acc\": f\"{test_results[0].get('test_acc'):.4f}\",\n",
    "        \"parameters\": countable_parameters,\n",
    "        \"grad_norm\": grad_norms,\n",
    "        \"layer_norm\": layer_norms,\n",
    "        \"total_norm\": f\"{total_norm:.4f}\",\n",
    "        \"norms_per_layer\": norms_per_layer,\n",
    "    }\n",
    "\n",
    "    results_dict.update({param:tmp_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN = \"\"\"\n",
    "\n",
    "Table of metrics for each of the models defined above.\n",
    "\n",
    "| model \\ specifications | Train Accuracy | Test Accuracy | Number of Trainable Parameters | Gradient Norm | Layerwise Norm | Total Parameter Norm | Per Layer Parameter Norm |\n",
    "|------------------------|----------------|---------------|--------------------------------|---------------|----------------|----------------------|--------------------------|\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in markdown table\n",
    "for name, metric in results_dict.items():\n",
    "    # print(f\"{name}: {metric}\")\n",
    "    MARKDOWN += f\"| **{name}** | {metric.get('train_acc')} | {metric.get('test_acc')} | {metric.get('parameters')} | {metric.get('grad_norm')} | {metric.get('layer_norm')} | {metric.get('total_norm')} | {metric.get('norms_per_layer')} |\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show table of metrics for each model\n",
    "md(MARKDOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_pt_model(model=ConvNet(params=params.get('model.2')),filename='models/model.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pt_model(model=ConvNet(params=params.get('model.2')),filename='test/model.2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adebayobraimah/Desktop/projects/fall2023project/.env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:480: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ff036794c444acb4b532355270ddd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9941458106040955     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.018992289900779724    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9941458106040955    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.018992289900779724   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b307adea9aa42c39953c3c5ea4656f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9944999814033508     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.017934512346982956    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9944999814033508    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.017934512346982956   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "print(f\"Training accuracy:\")\n",
    "train_results = trainer.test(model, dataloaders=train_loader)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(f\"Testing accuracy:\")\n",
    "test_results = trainer.test(model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
