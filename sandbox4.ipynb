{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchviz import make_dot\n",
    "\n",
    "from typing import Dict, Union\n",
    "from torch.jit.annotations import TensorType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do's\n",
    "\n",
    "- [] Add option to store gradient norm of each layer, stored separately\n",
    "- [X] Change linear layers to: CNN + 1 linear layer\n",
    "- [X] Make deep model (5 layers), and train it to perfection (up to 99% or higher train accuracy)\n",
    "- [X] Save the model (we’ll call this the “ground model”) (if time, create 5 ground models)\n",
    "- [] Then, create 10 models per noise level (pick 10 noise levels, between totally destroyed and basically no impact) (also loop through which layer)→ turns into 500 models. Make them noisy, measure all the things above (robustness, generalization.1, try generalization.2)\n",
    "- [] Can experiment with gradcam (interesting but not most important)\n",
    "\n",
    "\n",
    "Before Thr.\n",
    "\n",
    "- [X] Add option to store gradient norm of each layer, stored separately\n",
    "- [X] Create table, row -> model, col -> specs (grad norm, layerwise norm, specify train/test accuracy), list number of tunable parameters for each model.\n",
    "- [X] Add norms of total and/or per layer parameters to the table.\n",
    "- [] GradCam (wishlist or next step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download ``MNIST`` Dataset\n",
    "\n",
    "Download ``MNIST`` dataset, define training (80%), validation (10%), and test (10%) data sizes, and create the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset and dataloaders\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = torchvision.datasets.MNIST(root=os.getcwd(), train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, val, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=os.cpu_count())\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=os.cpu_count())\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network and ``LightningModule``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LightningModule\n",
    "class ConvNet(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # # Model 1\n",
    "            # nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            # \n",
    "            # # Model 2\n",
    "            # nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            # \n",
    "            # # Model 3\n",
    "            # nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # \n",
    "            # # Model 4\n",
    "            # nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # \n",
    "            # Model 5\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # NOTE: \n",
    "        #   [X] Try training with 32 all the way - see if model can still be 99% good\n",
    "        #   [?] Use a smaller model, smallest non-trivial model\n",
    "        #   [X] Reduce number of linear layers\n",
    "        #   [X] Start profiling (draw on piece of paper)\n",
    "        #   [] Look for number of weights in each model\n",
    "        #   Get model training up to 100% \n",
    "        #   \n",
    "        #   NOTE: Need atleast 2 linear layers - \n",
    "        #   NOTE: Find how to store/see: learning rate, validation error\n",
    "        # \n",
    "        # Want to avoid: did not scale step sizes, \n",
    "        # Want to find non-trivial conclusions\n",
    "\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            # # Model 1\n",
    "            # nn.Linear(256, 128),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128, 10),\n",
    "            #\n",
    "            # # Model 2\n",
    "            # nn.Linear(32, 10),\n",
    "            #\n",
    "            # # Model 3\n",
    "            # nn.Linear(32 * 3 * 3, 10),\n",
    "            # # Model 4\n",
    "            # nn.Linear(32 * 7 * 7, 10),\n",
    "            #\n",
    "            # Model 5\n",
    "            nn.Linear(14 * 14 * 32, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = x.view(x.size(0), x.size(1))  # Flatten the tensor along the channel dimension\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Lower lr from 0.001\n",
    "        # Try SGD\n",
    "        # GOAL: Get to 100% training error\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    # Define the training step method\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    # Define the validation step method\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.log('val_loss', loss, prog_bar=True)  # Logging the validation loss\n",
    "    \n",
    "    # Define the test step method\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "        self.log('test_loss', loss)  # Logging the test loss\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = (preds == targets).float().mean()\n",
    "        self.log('test_acc', acc, prog_bar=True)  # Logging the test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training, Validation, and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Lightning Trainer\n",
    "model = ConvNet()\n",
    "trainer = pl.Trainer(accelerator='mps',max_epochs=10,devices=1)  # Set max_epochs and gpus according to your environment\n",
    "\n",
    "# Train the model using PyTorch Lightning\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model: pl.LightningModule) -> int:\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8266d20ab72c46fa938eb28f03890b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9916666746139526     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0320788249373436     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9916666746139526    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0320788249373436    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 422,026\n"
     ]
    }
   ],
   "source": [
    "# Model 1 (6 layers, 4 Conv, 2 Linear)\n",
    "# \n",
    "# Evaluate the model on the test data\n",
    "trainer.test(model, dataloaders=test_loader)\n",
    "torch.save(model,'model.1.pt')\n",
    "print(f\"Number of trainable parameters (weights): {count_trainable_parameters(model=model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adebayobraimah/Desktop/projects/fall2023project/.env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:480: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3260c69f85374395b2e3eb125f15cd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9958750009536743     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01382284052670002    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9958750009536743    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01382284052670002   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 28,394\n"
     ]
    }
   ],
   "source": [
    "# Use trainer.test with the test_loader [Train Error]\n",
    "# Model 1 (6 layers, 4 Conv, 2 Linear)\n",
    "# \n",
    "# Evaluate the model on the test data\n",
    "# \n",
    "# NOTE: Stick with model.2\n",
    "model = torch.load('model.2.pt')\n",
    "trainer.test(model, dataloaders=train_loader)\n",
    "print(f\"Number of trainable parameters (weights): {count_trainable_parameters(model=model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf320332b9c4f12b71dd3989eb2537e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9898333549499512     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.035352300852537155    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9898333549499512    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.035352300852537155   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 28,394\n"
     ]
    }
   ],
   "source": [
    "# Model 2 (5 layers, 4 Conv, 1 Linear)\n",
    "# \n",
    "# Evaluate the model on the test data\n",
    "trainer.test(model, dataloaders=test_loader)\n",
    "torch.save(model,'model.2.pt')\n",
    "print(f\"Number of trainable parameters (weights): {count_trainable_parameters(model=model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6fecebf78f4f58bcb8b369b9503438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9898333549499512     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03892754018306732    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9898333549499512    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03892754018306732   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 21,706\n"
     ]
    }
   ],
   "source": [
    "# Model 3 (4 layers, 3 Conv, 1 Linear)\n",
    "# \n",
    "# Evaluate the model on the test data\n",
    "trainer.test(model, dataloaders=test_loader)\n",
    "torch.save(model,'model.3.pt')\n",
    "print(f\"Number of trainable parameters (weights): {count_trainable_parameters(model=model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8382ad6e993427ca54880bc1507886a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9851666688919067     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.060679841786623     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9851666688919067    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.060679841786623    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 25,258\n"
     ]
    }
   ],
   "source": [
    "# Model 4 (3 layers, 2 Conv, 1 Linear)\n",
    "# \n",
    "# Evaluate the model on the test data\n",
    "trainer.test(model, dataloaders=test_loader)\n",
    "torch.save(model,'model.4.pt')\n",
    "print(f\"Number of trainable parameters (weights): {count_trainable_parameters(model=model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0694f943aa04cd6bfa572bf551c7fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9806666374206543     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07913394272327423    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9806666374206543    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07913394272327423   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters (weights): 63,050\n"
     ]
    }
   ],
   "source": [
    "# Model 5 (2 layers, 1 Conv, 1 Linear)\n",
    "# \n",
    "# Evaluate the model on the test data\n",
    "trainer.test(model, dataloaders=test_loader)\n",
    "torch.save(model,'model.5.pt')\n",
    "print(f\"Number of trainable parameters (weights): {count_trainable_parameters(model=model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_model(model: pl.LightningModule, noise_factor: float = 0.01) -> None:\n",
    "    # TODO: Return new updated noise model\n",
    "    # \n",
    "    # Will need to make deep copy of model\n",
    "    # Create new reference variable to deep copied\n",
    "    #   model\n",
    "    # NOTE: noise_factor, treat in log-way, logE-8 -> 1\n",
    "    # \n",
    "    # Want to see model learning, just not learning well\n",
    "    # Need to know the norms of parameters\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            noise = torch.randn_like(param) * noise_factor\n",
    "            param.add_(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_and_viz_pl_model(model: pl.LightningModule, filename: str) -> None:\n",
    "#     # Create a dummy input with the same shape as expected input during training\n",
    "#     dummy_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "#     # Generate the visualization of the model architecture\n",
    "#     dot = make_dot(model(dummy_input))\n",
    "#     params = dict(model.named_parameters())\n",
    "\n",
    "#     # Save the visualization as an image\n",
    "#     dot.format = 'png'\n",
    "#     dot.render(filename, cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_and_viz_pl_model(model=model,\n",
    "#                       # filename='model.1.4_ConvLayers.2_LinLayer',\n",
    "#                       # filename='model.2.4_ConvLayers.1_LinLayer',\n",
    "#                       # filename='model.3.3_ConvLayers.1_LinLayer',\n",
    "#                       # filename='model.4.2_ConvLayers.1_LinLayer',\n",
    "#                       filename='model.5.1_ConvLayers.1_LinLayer',\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('model.5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_layers.0.weight',\n",
       "              tensor([[[[-0.3202, -0.1778,  0.0620],\n",
       "                        [ 0.2234,  0.0629,  0.1850],\n",
       "                        [-0.1793, -0.2067, -0.0119]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0726, -0.0674, -0.2367],\n",
       "                        [-0.0923, -0.2490,  0.1725],\n",
       "                        [-0.2860, -0.0074,  0.1166]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0516,  0.3071,  0.2535],\n",
       "                        [ 0.0649,  0.2776, -0.0090],\n",
       "                        [-0.2020, -0.1665, -0.2772]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1691,  0.1573,  0.1057],\n",
       "                        [-0.2105, -0.1876, -0.1378],\n",
       "                        [-0.0705, -0.1706, -0.1636]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2299,  0.1070, -0.3222],\n",
       "                        [-0.1409, -0.2790,  0.1478],\n",
       "                        [ 0.2875, -0.0482,  0.0777]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1939, -0.1058,  0.3098],\n",
       "                        [ 0.2493, -0.1873,  0.1527],\n",
       "                        [-0.0028,  0.0399, -0.2060]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2012, -0.1750,  0.1838],\n",
       "                        [ 0.0469, -0.0856, -0.1326],\n",
       "                        [ 0.2059,  0.0317, -0.2136]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1225,  0.0665, -0.0600],\n",
       "                        [-0.2917,  0.0836, -0.0124],\n",
       "                        [-0.0333,  0.2617,  0.0897]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0635, -0.3007, -0.2233],\n",
       "                        [-0.1145,  0.2429,  0.2142],\n",
       "                        [ 0.1920, -0.2236, -0.0126]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2489, -0.1196, -0.0432],\n",
       "                        [ 0.1051, -0.3309, -0.1227],\n",
       "                        [ 0.3080, -0.2782,  0.0710]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1023, -0.2179, -0.0833],\n",
       "                        [-0.1978,  0.2794,  0.1058],\n",
       "                        [-0.0479, -0.2456,  0.0574]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2882, -0.0690, -0.2658],\n",
       "                        [ 0.2383, -0.0785,  0.1725],\n",
       "                        [-0.0317,  0.1016,  0.3058]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0507,  0.2424,  0.2873],\n",
       "                        [ 0.0816, -0.1789, -0.0341],\n",
       "                        [-0.1428,  0.1006,  0.1185]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1700,  0.1955,  0.2414],\n",
       "                        [-0.0274,  0.2374, -0.0175],\n",
       "                        [-0.1496,  0.0404, -0.0983]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1830, -0.1738, -0.3251],\n",
       "                        [ 0.0385, -0.0204, -0.0877],\n",
       "                        [ 0.2432, -0.3237,  0.0323]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1747, -0.1368, -0.2167],\n",
       "                        [-0.2999, -0.2544, -0.2899],\n",
       "                        [ 0.0623,  0.1353, -0.2574]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0971,  0.1316,  0.0133],\n",
       "                        [ 0.3271,  0.1580,  0.2361],\n",
       "                        [ 0.1294, -0.1761,  0.0634]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1814,  0.2856,  0.2500],\n",
       "                        [-0.1684,  0.1970, -0.2199],\n",
       "                        [ 0.1805, -0.0677,  0.1538]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2403, -0.1451,  0.1713],\n",
       "                        [-0.2952, -0.1273,  0.1300],\n",
       "                        [-0.2730, -0.0559,  0.2956]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2591, -0.1131,  0.0213],\n",
       "                        [-0.2387,  0.0604, -0.0561],\n",
       "                        [-0.1038,  0.0640,  0.3236]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2703, -0.2331, -0.0817],\n",
       "                        [-0.2144,  0.1660, -0.2280],\n",
       "                        [-0.2147, -0.1383, -0.2457]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2942, -0.1237,  0.2046],\n",
       "                        [-0.0569, -0.1096, -0.1928],\n",
       "                        [-0.0559, -0.2458,  0.2031]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0211, -0.0358, -0.1929],\n",
       "                        [ 0.3146, -0.1508,  0.1293],\n",
       "                        [-0.1650,  0.1807, -0.1602]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0650,  0.0326,  0.1452],\n",
       "                        [-0.1085, -0.1187, -0.0959],\n",
       "                        [-0.2364, -0.2545, -0.0017]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0085,  0.3018,  0.1930],\n",
       "                        [-0.0286, -0.3267, -0.2903],\n",
       "                        [ 0.1678, -0.0760,  0.2161]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0167, -0.3128, -0.1565],\n",
       "                        [-0.1889, -0.1568, -0.3175],\n",
       "                        [ 0.3244, -0.1571, -0.0642]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3295, -0.2773,  0.0513],\n",
       "                        [-0.2497, -0.2307, -0.2097],\n",
       "                        [-0.2268,  0.2706,  0.2431]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1078, -0.0409,  0.2943],\n",
       "                        [-0.1185, -0.0276, -0.0746],\n",
       "                        [ 0.2652,  0.1683, -0.0043]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2544,  0.0036, -0.0481],\n",
       "                        [-0.1477, -0.2757,  0.2706],\n",
       "                        [-0.0879,  0.1121,  0.0197]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0232, -0.1149, -0.1737],\n",
       "                        [-0.0196, -0.1078, -0.0153],\n",
       "                        [ 0.0807, -0.1855,  0.1782]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0512, -0.2410, -0.1330],\n",
       "                        [ 0.1799, -0.1370,  0.2243],\n",
       "                        [-0.1457, -0.2278, -0.1461]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2786, -0.1935, -0.2230],\n",
       "                        [-0.3123, -0.3194, -0.1901],\n",
       "                        [ 0.0697, -0.2879, -0.1239]]]])),\n",
       "             ('conv_layers.0.bias',\n",
       "              tensor([ 0.3274,  0.1838, -0.3202, -0.2730, -0.2413,  0.3317,  0.1369,  0.1259,\n",
       "                       0.1707,  0.1001, -0.2039, -0.0508, -0.0507, -0.1355,  0.0452,  0.3099,\n",
       "                       0.1039, -0.0102, -0.3004,  0.1737,  0.2590,  0.0483,  0.1539, -0.2121,\n",
       "                       0.0083, -0.0040,  0.3279,  0.2190,  0.2836, -0.1597, -0.0927, -0.2283])),\n",
       "             ('fc_layer.0.weight',\n",
       "              tensor([[ 4.9598e-03,  1.0306e-02,  4.7572e-03,  ..., -1.0118e-02,\n",
       "                       -3.4706e-03, -5.6088e-03],\n",
       "                      [-4.0450e-03,  1.0059e-03, -1.0328e-02,  ...,  2.0381e-03,\n",
       "                        6.3759e-03, -6.6233e-03],\n",
       "                      [ 1.1756e-02, -9.3494e-03,  1.2362e-02,  ..., -2.5195e-03,\n",
       "                       -2.3905e-03, -5.5120e-05],\n",
       "                      ...,\n",
       "                      [ 3.3480e-03,  9.6687e-03, -1.2450e-02,  ...,  1.0046e-02,\n",
       "                       -6.4262e-03,  1.1679e-02],\n",
       "                      [-1.2306e-02,  8.7030e-03,  1.1451e-02,  ...,  4.7806e-03,\n",
       "                       -2.7582e-04,  4.4387e-03],\n",
       "                      [ 7.0051e-03, -1.1715e-02,  9.1962e-03,  ...,  1.8193e-03,\n",
       "                       -7.7321e-03,  8.4668e-04]])),\n",
       "             ('fc_layer.0.bias',\n",
       "              tensor([-0.0095, -0.0094, -0.0093,  0.0106, -0.0045, -0.0064,  0.0117, -0.0016,\n",
       "                       0.0106,  0.0103]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_and_viz_pl_model(model: Union[nn.Module,pl.LightningModule], filename: str) -> None:\n",
    "    \"\"\"Helper function to visualize and plot the model architecture.\n",
    "\n",
    "    Args:\n",
    "        model: Input pytorch (lightning) model.\n",
    "        filename: Output filename (no file extension).\n",
    "    \"\"\"\n",
    "    # Create a dummy input with the same shape as expected input during training\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "    # Generate the visualization of the model architecture\n",
    "    dot = make_dot(model(dummy_input))\n",
    "    # params = dict(model.named_parameters())\n",
    "\n",
    "    # Save the visualization as an image\n",
    "    dot.format = 'png'\n",
    "    dot.render(filename, cleanup=True)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pt_model(model: Union[nn.Module,pl.LightningModule], filename: str) -> None:\n",
    "    \"\"\"Saves pytorch (lightning) model, and creates visualization of model architecture.\n",
    "\n",
    "    Args:\n",
    "        model: Input pytorch (lightning) model.\n",
    "        filename: Output filename.\n",
    "    \"\"\"\n",
    "    # TODO: Save metadata file for the model.\n",
    "    # Check filename\n",
    "    filename: str\n",
    "    ext: str\n",
    "    \n",
    "    if ('pt' or 'pth') in filename:\n",
    "        filename, ext = os.path.splitext(filename)\n",
    "    else:\n",
    "        ext: str = \".pt\"\n",
    "    \n",
    "    # Save model (and model state)\n",
    "    torch.save(model.state_dict(), f\"{filename}{ext}\")\n",
    "\n",
    "    # Save image of model architecture\n",
    "    _save_and_viz_pl_model(model=model, filename=filename)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pt_model(model: Union[nn.Module,pl.LightningModule], filename: str) -> Union[nn.Module,pl.LightningModule]:\n",
    "    \"\"\"Loads saved/trained model, in which the model class **must** be provided.\n",
    "\n",
    "    Args:\n",
    "        model: Input model class objoect.\n",
    "        filename: Input filename that corresponds to trained saved/trained model.\n",
    "\n",
    "    Returns:\n",
    "        Trained model.\n",
    "    \"\"\"\n",
    "    # model = TheModelClass(*args, **kwargs)\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    model.eval() # sets dropout and batch normalization layers to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class '__main__.ConvNet'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m \u001b[39m=\u001b[39m load_pt_model(model\u001b[39m=\u001b[39;49mmodel,filename\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodel.5.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m, in \u001b[0;36mload_pt_model\u001b[0;34m(model, filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_pt_model\u001b[39m(model: Union[nn\u001b[39m.\u001b[39mModule,pl\u001b[39m.\u001b[39mLightningModule], filename: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[nn\u001b[39m.\u001b[39mModule,pl\u001b[39m.\u001b[39mLightningModule]:\n\u001b[1;32m      2\u001b[0m     \u001b[39m# model = TheModelClass(*args, **kwargs)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(filename))\n\u001b[1;32m      4\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Desktop/projects/fall2023project/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1994\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Copies parameters and buffers from :attr:`state_dict` into\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m \u001b[39mthis module and its descendants. If :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m \u001b[39mthe keys of :attr:`state_dict` must exactly match the keys returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[39m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 1994\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected state_dict to be dict-like, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(state_dict)))\n\u001b[1;32m   1996\u001b[0m missing_keys: List[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[1;32m   1997\u001b[0m unexpected_keys: List[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class '__main__.ConvNet'>."
     ]
    }
   ],
   "source": [
    "m = load_pt_model(model=model,filename='model.5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.5.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('pt' or 'pth') in filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,e = os.path.splitext(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.5.pt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f+e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"model.5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type ConvNet is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel.5.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     json\u001b[39m.\u001b[39;49mdump(model, f, indent\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/projects/fall2023project/.env/lib/python3.11/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(skipkeys\u001b[39m=\u001b[39mskipkeys, ensure_ascii\u001b[39m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[39m=\u001b[39mcheck_circular, allow_nan\u001b[39m=\u001b[39mallow_nan, indent\u001b[39m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[39m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[39m=\u001b[39mdefault, sort_keys\u001b[39m=\u001b[39msort_keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\u001b[39m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[39m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[39m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/Desktop/projects/fall2023project/.env/lib/python3.11/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCircular reference detected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[39m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[39m=\u001b[39m _default(o)\n\u001b[1;32m    440\u001b[0m \u001b[39myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/projects/fall2023project/.env/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ConvNet is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open(\"model.5.json\", \"w\") as f:\n",
    "    json.dump(model, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layers.0.weight\n",
      "conv_layers.0.bias\n",
      "fc_layer.0.weight\n",
      "fc_layer.0.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'generator' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49msave(model\u001b[39m.\u001b[39;49mnamed_parameters(), \u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/projects/fall2023project/.env/lib/python3.11/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    440\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/projects/fall2023project/.env/lib/python3.11/site-packages/torch/serialization.py:653\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    651\u001b[0m pickler \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mPickler(data_buf, protocol\u001b[39m=\u001b[39mpickle_protocol)\n\u001b[1;32m    652\u001b[0m pickler\u001b[39m.\u001b[39mpersistent_id \u001b[39m=\u001b[39m persistent_id\n\u001b[0;32m--> 653\u001b[0m pickler\u001b[39m.\u001b[39mdump(obj)\n\u001b[1;32m    654\u001b[0m data_value \u001b[39m=\u001b[39m data_buf\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    655\u001b[0m zip_file\u001b[39m.\u001b[39mwrite_record(\u001b[39m'\u001b[39m\u001b[39mdata.pkl\u001b[39m\u001b[39m'\u001b[39m, data_value, \u001b[39mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'generator' object"
     ]
    }
   ],
   "source": [
    "torch.save(model.named_parameters(), 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=6272, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
